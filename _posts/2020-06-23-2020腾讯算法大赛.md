---
layout:     post
title:      腾讯广告算法大赛
subtitle:   小菜鸡冲100名
date:       2020-06-23
author:     Noah-Yiliu
header-img: img/taitou.jpg
catalog: true
tags:
    - 数据挖掘
    - 竞赛
---

# 腾讯广告算法大赛

本博客记录了2020年腾讯广告算法大赛的一些解题思路，这些思路和解法综合了各路大神所提建议以及个人的一些想法，最终比赛得分在1.41左右（我满足了，如果有足够时间进行参数调整可能分数会进一步提高）。这里只贴出部分关键代码。

## 比赛介绍

本届算法大赛的题目来源于一个重要且有趣的问题。众所周知，像用户年龄和性别这样的人口统计学特征是各类推荐系统的重要输入特征，其中自然也包括了广告平台。**这背后的假设是，用户对广告的偏好会随着其年龄和性别的不同而有所区别**。许多行业的实践者已经多次验证了这一假设。然而，大多数验证所采用的方式都是以人口统计学属性作为输入来产生推荐结果，然后离线或者在线地对比用与不用这些输入的情况下的推荐性能。本届大赛的题目尝试从另一个方向来验证这个假设，即以用户在广告系统中的交互行为作为输入来预测用户的人口统计学属性。

![](https://github.com/awzsse/awzsse.github.io/blob/master/img/tencentcomp.png?raw=true)

具体而言，本赛题为参赛者提供一组用户在长度为91天(3个月)的时间窗口内的**广告点击历史记录**作为**训练数据集**。每条记录中包含了**日期**（从1到91）、**用户信息**（年龄，性别），**被点击的广告的信息**（素材 id、广告 id、产品 id、产品类目 id、广告主id、广告主行业id等），以及**该用户**当天点击该广告的次数**。测试数据集将会是另一组用户的广告点击历史记录。提供给参赛者的**测试数据集中**不会包含这些用户的年龄和性别信息**。本赛题要求参赛者预测测试数据集中出现的用户的年龄和性别，并以约定的格式提交预测结果。

## 单模型

### 特征初探

从上面的介绍中我们可以看出，**被点击的广告信息**是我们这次主要的处理对象。如下图所示，这里包含的六个特征中，有四个特征明显包含了绝大多数的信息，分别是**ad_id**，**creative_id**，**industry**以及**advertise_id**。其余的两个特征例如**推广商品的类型**，可能并不会直接影响商品类型，例如京东，淘宝等平台都会上同类型的商品，因此我们可以暂时不做考虑，而商品ID由于存在过多的缺失值，我们也暂时放在一边。

![](https://github.com/awzsse/awzsse.github.io/blob/master/img/tencentfeature.jpg?raw=true)

下面我们对这四个特征排个序，分别是：

> 1. creative_id，该特征保存了最多的商品细节信息
> 2. ad_id
> 3. advertise_id
> 4. industry

### 特征工程

本次训练集给出的数据有90万条，而测试集有100万条。以**creative_id**为例，其取值范围为**58万**个不同类型的广告素材id，如果我们通过简单的**one-hot**方法将会创造大量的新特征，模型训练压力太大。而**ad_id**也拥有着相似的问题。因此传统的特征工程无法很好的或者可供训练的特征。结合各路大神的思路，我们决定通过**word2vec**方法将每个用户点击的所有广告素材id的组合变成**句子向量**。这样说可能有点抽象，我们带着部分代码进行解释。

首先，**word2vec**是在**nlp**领域常用的技术之一。如下图所示，假设已知**creative_id**中拥有的所有58万个类别取值，例如某个商品为'300001'，我们就将其视为一个单词，它的初始形式可以看作一个58万位的数值：$0....0001$，也就是只有$x_n$这一位是$1$。那么我们通过**word2vec**模型将其变成固定维度的向量，并且期望这个向量可以尽量保存原有的词信息。

![](https://github.com/awzsse/awzsse.github.io/blob/master/img/w2v.png?raw=true)

这里需要注意的是，由于我们训练集以及测试集可能存在不同的“**词语**”，因此我们这个58万个类别取值是包含了训练集以及测试集所有的取值。那么句子向量是如何计算的呢？我们使用简单的加权均值，也就是说每个用户针对每个单词的**点击次数**作为权重值，最后算出来所有词语的**加权均值**就是整个该用户点击过所有单词组成句子的**句子向量**。代码如下：

```python
# 这里的texts是处理完的词向量

# w2v_dim是定义的词向量维度

# weights是每个单词的点击次数

for i, line in enumerate(texts):
        num = 0
        if line == '':
            w2v_feature_avg[i, :] = np.zeros(w2v_dim)
        else:
            for word in line:
                # 加权平均
                vec = model[word] if word in vacab else np.zeros(w2v_dim)
                w2v_feature[i, :] += vec*weights[i][num]
                w2v_feature_avg[i, :] = w2v_feature[i, :] / sum(weights[i])
                num += 1
```

针对其他特征，例如针对取值较多的特征，我们仍然使用w2v方法，而针对其他的特征我们会使用**tf-idf**以及简单的统计学处理方法处理。这里简单说一下**tf-idf**方法。其中**tf**指的是**词频**，也就是某个单词在文章中出现的次数，往往再除以文章总词数做一个标准化，这代表了这个词语的频率，容易理解，当这个值越高，某些层面上表明这个词越重要，但是这并不完整，因为可能类似a,the等词会经常出现，但是并不是关键词，这时候需要把词频和另一个关键值**idf**做一个结合，该关键值又称为**逆文档频率**。我们假定有一个语料库，那么这个值就等于$log\frac{语料库的文档总数}{包含该词的文档数+1}$。我们可以看到，当这个词语出现在越多文章中，这个值就越小，表明这个词很有可能是不重要的无用词。因此通过tf与idf的相乘，我们可以得到最终的一个词语重要性。通过**tf-idf**加权平均法我们可以得到每个句子的句子向量，作为特征使用。

关于**tf-idf**加权平均法[这里](https://www.cnblogs.com/Kalafinaian/p/11300953.html)有提到。

### 模型选择

由于数据较大，我们使用了速度较快的**lightGBM**作为单模尝试，结果发现，即便是单模，单特征（creative_id），我们也得到了相当不错的结果。同时我们还使用了简单的**nn**网络，结果相差不大。

## 其他特征以及混合模型

我们后期还针对不同特征的组合以及不同模型的融合做出了尝试。请看下面这张图片：

![感谢小伙伴们提供的思维导图](https://github.com/awzsse/awzsse.github.io/blob/master/img/tencentmodels.png?raw=true)

这里需要提到的是：

1. 针对处理完的特征，我们使用不同模型去预测，将预测结果作为新的特征，最后一起放入**lstm**或者简单的**nn**网络进行预测。

2. 预测的时候可以使用两种方法。其一就是先预测**年龄/性别**，再使用预测结果去预测**性别/年龄**。亦或是如图中所示，直接将年龄的10个类别以及性别的两个类别变成一个20分类问题进行预测。

## 总结

通过word2vec以及tfidf方法处理了大部分特征，使用单模或者模型融合方法进行训练，可以得到较好的训练效果。希望本博客可以给未来参加各类竞赛的同学一点启发。
