---
layout:     post
title:      2020年春机器学习面试总结（持续更新）
subtitle:   好记性不如烂笔头
date:       2020-04-13
author:     Noah-Yiliu
header-img: img/taitou.jpg
catalog: true
tags:
    - 面试
---

# 机器学习面试总结
本篇是为了最近找工作顺便整理的面试总结，引用来源比较复杂我会一一列出。内容比较多，包含了基本的数理统计知识，机器学习方法比较，深度学习方法，python基础，python数据结构，数据库等内容。基本都是常问，常考题（不断更新）

## 偏差方差
首先我们训练一个数据集后会得到某个模型，那么这个模型对于这个**训练集**的损失和与**真实值**之间的损失的差异称为**泛化误差**。

> 泛化误差可以分解为**偏差**，**方差**以及**噪声**。

**方差**的含义：方差度量了同样大小的训练集的变动所导致的学习性能的变化，即刻画了**数据扰动**所造成的影响。

**偏差**的含义：偏差度量了学习算法的期望预测与真实结果的偏离程度，即刻画了学习算法本身的拟合能力。

**噪声**的含义：噪声则表达了在当前任务上任何学习算法所能达到的期望泛化误差的下界，即刻画了学习问题本身的难度。

一、过拟合表示高方差，低偏差，欠拟合表示低方差，高偏差。

二、偏差-方差之间是存在冲突的，称为**偏差-方差窘境**，需要trade-off。

三、Bagging（Bootstrap Aggregating）通过有放回抽样的方法产生不同子集去训练数据，可以显著降低模型的方差，random forest也有类似的作用。而Boosting是一种迭代算法，是通过每次去拟合**现有模型**产生的残差或者负梯度，利用加法模型去更新新的子模型，这样一来会产生比较低的偏差，对数据拟合较好。特别提出，GBDT中每个子模型都是高偏差，低方差的，因此总体模型的方差也不会太高。

（插眼，GBDT为什么不容易过拟合）

四、k折交叉验证中，如果k比较大，那么也就是说我们运用到的训练数据更多，偏差小，拟合程度好，但是方差会大。如果当k较小，不会过度拟合数据，但是偏差大，方差小。

## GBDT
本质上来说，GBDT使用满足高偏差的默认分类器也就是CART TREE作为子分类器，通过迭代的方法不断拟合上一轮的残差得到最终的分类器。该方法满足**经验风险最小化**。

一、训练方法：如果当损失函数是**平方损失函数**的时候，我们直接拟合上一轮的残差即可。如果是别的损失函数，我们可以利用**负梯度**作为近似值去拟合一个树。这样做可以以最快的使得损失函数减小。

二、GBDT的选择特征过程：每个子树的生成过程**都是**一个**特征选择**过程，通过依次寻找到子树每个节点的最优切分点以及切分变量，使得切分后两边数据的均方误差和最小。根据我们设定好的最大深度以及最大叶子节点数量，我们得到一颗子树加入到加法模型中。

三、GBDT可以用于构建特征：**Facebook** 在2014年发表的一篇论文尝试了利用GBDT去产生有效的特征组合，也就是**GBDT+LR**产生的**CTR**模型结构。具体的，我们通过将不同的输入x输入到GBDT的每个子树的各个子节点中，将该子节点命名为1，其余为零，构成**特征向量**（假设两个子树四个节点为[0,0,1,0]，[0,1,0,0]），那么这样一来我们将所有这些特征向量做一个拼接（[0,0,1,0,0,1,0,0]），再放入LR模型中训练出CRT。经证实，这种方法可以非常有效的做出模型提升，同时子树规模大概为600的时候效果最好。

四、GBDT用于分类树：同样也是运用回归树来做分类任务，这里因为我们每轮要去拟合残差（负梯度），但是这残差必须是有意义的，如果我们用分类标签去相减的话就没有什么意义。具体的算法可以参考[这个博客](https://blog.csdn.net/qq_22238533/article/details/79199605)，这边做出简单的总结。

* 我们假设需要做三个类的分类，那么我们针对每一个样品都训练三个模型，每个模型针对某一个类。具体的，我们将样本的标签变成[1,0,0],[0,1,0],[0,0,1]的形式，代表分别属于这三个类，那么我们训练第一个类型的树，只需要用到第一维的标签。比如有三个上面的样本标签，我们使用$（x_1,1）$,$(x_2，0)$,$（x_1，0）$。
* 我们还是根据均方误差去选择这第一棵树的每个节点，最终将所有的数据点落入不同的叶子节点中，根据特定规则（比如求标签的平均值）作为每个叶子节点的输出。然后再去训练第二棵树，第三棵树。。
* 当训练完所有类别的第一棵树以后，根据负梯度继续拟合每个类别的第二棵树。最终得到又M个弱分类器组成强分类器，这样的强分类器有3个。
* 最后，我们对于输入的数据，计算每个类别产生的输出和作为数据属于每个类别的预测值，再将这些预测值进行softmax转换，变成一个概率值，最终得到数据分类。

五、GBDT跟SVM，LR对比：
* 首先对于GBDT和SVM来说，他们对于outlier都有很好的鲁棒性，怎么理解呢？对于GBDT来说，我们每个节点都是$x<X$这种形式，所以对于极端值的大小不会对模型产生过大影响；对于SVM来说，对数据的分类只依赖于某几个点，因此可能不会受到很大影响。然而我们自习考虑一下LR，按照梯度上升更新权重的时候，需要用到每个数据，如果出现极端数据，其参数更新的梯度会趋近于零，因此如果这些点是误分类点的话，整个模型对其作出的修正就会比较小。
* GBDT可以天然做出特征选择，比如无关的feature可以不出现在树里面，但是SVM以及LR就没有这样的特性
* GBDT由于对弱分类器的要求不高，弱分类器不会太复杂，因此对于大数据量，我们对于小分类器的做出的操作不会太复杂，但是SVM这种当数据规模比较大的时候，训练起来会比较麻烦。
* 当然GBDT也不是一直好用，当数据不带噪音的时候，他能达到的最佳分类效果还是没有SVM，LR好。

## SVM
针对SVM其实主要是要理解他内部的逻辑，基本要求是可以手推线性支持向量机中目标函数，拉格朗日方程，对偶问题以及最后求解参数等。其次还需要了解他的基本特性以及与别的机器方法之间的异同。由于我们手推部分基本已经完成了，主要收集整理一下别的常用问的面试题目。

一、SVM如何防止过拟合：由于SVM的分离超平面是由少数几个点决定的，那么如果这几个点中存在着异常值，这时允许的$\xi$越大，说明我们对这种异常点的容忍程度就会更大，也就不容易让整个超平面收到影响，从而防止过拟合的发生。因此我们可以降低调节因子$C$的大小。

二、SVM的超参有哪些：$C$和$\gamma$，其中$C$是作为惩罚系数加入到目标函数中，而$\gamma$是核函数里的参数，也决定着支持向量的数量。

三、SVM核函数：主要包括高斯核函数（RBF），多项式核函数，线性核函数以及指数核函数。其中，线性核函数的形式实际上就是两个样本的内积，因此这是用在线性支持向量机中的。

四、为什么要转化成对偶形式：首先是为了方便核函数的引入，其次通过间接求解$\alpha$的值从而得到$w，b$，可以很大程度上简化计算过程。

## python的数据结构

一、python的数据结构有哪些呢？

首先是几个基本数据结构，包括**序列**（列表，元组，字符串），**映射**（字典）以及集合。另外，还包括**链表，队列，栈**等。

二、列表，链表有什么区别？

* 列表是一种内存连续的线性结构，可以随机访问。也就是查找，尾部添加以及尾部pop的时间复杂度为O(1)，而插入和删除的平均时间复杂度为O(n)。

* 链表是内存**不连续**的链式结构，单链表的首部，尾部添加的时间复杂度都是O(1)，然而他的查找和删除的平均时间复杂度为O(n)，当然如果知道需要删除的某个节点是哪个，就只需要O(1)。

* 单链表和双向链表的区别是双向链表的属性中还多了**指向前一个链表节点**的指针。

三、哈希表有点东西？

我们之前提到，列表删除元素需要移动别的元素，很麻烦，链表中如果知道需要删除的节点是哪个，那么我们可以直接删除，但是链表查找元素又没有列表那么方便。哈希表就很好的解决了这个问题。他通过给一个哈希函数，计算出每一个元素的逻辑下标，也就是该元素应该放在数组的哪个位置。

* 哈希冲突：我们对元素进行哈希后，可能会发现不同的元素拥有了相同的逻辑下标，这时就称为哈希冲突，比较常见的解决办法称为***链接法***，通过在冲突位置延申出一个链表，用来顺序记录，但是如果链表太长了，查找就不再是O(1)了，这时候我们可以使用另一种方法叫做***开放寻址法***，也就是当一个位置被占用，我们通过在原始计算位置上进行再次探查的方法找到新的位置。

* 装载因子：我们开辟的散列空间装载元素的程度，假设我们开辟了10个位置，装载了8个元素，这时候装载因子就是0.8了，这时候我们就需要重新开辟新空间进行散列。

* 重哈希：重哈希就是重新开辟新空间的过程，不同版本的cpython会使用不同的策略，比如python3.3是扩大已经使用的槽数的两倍。

四、哈希表的应用

实际上我们之前提到的**字典**以及**集合**，他的底层都是由哈希表构成的，其中字典这种以键值对组成的数据结构，其键必须是**可哈希**的，也就是不可变的，例如如果是列表就不行了。对于**集合**来说，他的操作比字典更加丰富，可以做交，并，补，差等。

五、递归方法概论

递归包含三个基本特点。首先我们一定需要一个基本出口，否则会无线递归；其次，一定要包含一个可以分解的问题，比如求阶乘的时候我们求$f(n)$需要通过求解$n\times f(n-1)$得到；最后，一定要朝着出口附近靠近，我们总不能求$f(n+1)$，这样离$n=0$越来越远。

电脑解决递归问题会***调用栈***。简单思考一下，我们每次进入递归函数的时候，系统都会为这个新的函数开辟内存保存当前变量的信息，直到找到递归出口才会一个一个出栈。

六、查找方法！！

* 线性查找：针对无序的序列，比如无序的列表，元组等。直接遍历查找，找到返回index即可。

* **二分查找**：如果一个序列已经是排序好的，我们怎么取呢？再用线性查找方法岂不是有带你浪费了排序算法。我们通过每次选取中间index的方法查找元素。具体代码如下：

```python
def binary_search(sorted_array, val):
    # 首先判断是不是为空

    if not sorted_array:
        return -1
    beg = 0
    end = len(sorted_array)-1
    # 循环退出条件

    while beg<=end:
        # 这里是向下取整

        mid = (beg+end)/2
        if sorted_array[mid] == val:
            return mid
        elif sorted_array[mid] < val:
            beg = mid+1
        else:
            end = mid-1
    return -1
```
这里我们看到当mid位置的值比我们的目标值小的时候，我们直接从它后一位开始寻找，这样每次都可以舍弃一半的无用值。他的查找时间复杂度为O(logN)。当然，这一切都建立在已经有排序好的数组基础上。


七、排序方法-堆排序

这里我之所以先提到了堆排序，是因为正好刷到leetcode的一道题--***TopK问题***。也就是给出一个列表，要我们找出第k大的元素的值。大家肯定会有疑问，这直接排序完了再以k-1作下标不就选出来了嘛？话是这么说没错，但是这样的时间复杂度怎么找也大于nlogn了，也就是排序最快的平均时间复杂度。我们可不可以找出一个更快的排序方式呢？答案是肯定的，那就是通过堆排序，最后返回最小堆的根节点就好。

首先我们要说明一下，什么是**堆**？堆其实就是一个完全二叉树，也就是按照一层一层从左到右没有间隙的二叉树。因此他可以通过列表直接表示出来。

例如下图$^{[4]}$:

![](https://github.com/awzsse/awzsse.github.io/blob/master/img/heap.png?raw=true)

其实python自带了一个最小堆的包，我们可以直接使用，因为是标准库：

```python
import heapq
```
利用这个库，我们可以通过这个类定义的一些方法去创造一个heap，这个heap就是个列表形式，我们可以添加元素，可以提取堆顶元素，具体的方法如下：

```python
> heapq.heappush(heap, item) 把item添加到heap中（heap是一个列表）

> heapq.heappop(heap) 把堆顶元素弹出，返回的就是堆顶

> heapq.heappushpop(heap, item) 先把item加入到堆中，然后再pop，比heappush()再heappop()要快得多

> heapq.heapreplace(heap, item) 先pop，然后再把item加入到堆中，比heappop()再heappush()要快得多

> heapq.heapify(x) 将列表x进行堆调整，默认的是小顶堆

> heapq.merge(*iterables) 将多个列表合并，并进行堆调整，返回的是合并后的列表的迭代器

> heapq.nlargest(n, iterable, key=None) 返回最大的n个元素（Top-K问题）

> heapq.nsmallest(n, iterable, key=None) 返回最小的n个元素（Top-K问题）
```

在这个类下这些操作结束都会自动去维护新的堆使之满足堆的特性。下面，我们利用这个标准库可以实现TopK的算法：

```python
def findKthLargest(nums,k):
    # 由于可以直接使用最小堆包
    
    # 先进行push步
    
    # 首先定义一个用来装小顶堆的list
    heap = []
    
    # 再判断，这个heap的长度如果大于k的时候，我们就不能直接push了
    
    # 需要判断是replace还是pass
    
    for val in nums:
        if len(heap)<k:
            heapq.heappush(heap,val)
        else:
            if val<heap[0]:
                pass
            else:
                heapq.heapreplace(heap, val)
    
    # 这样一来就建立了一个小顶堆
    
    # 下面我们只需要返回这个小顶堆的第一个元素就行了
    
    return heap[0]
```
这里分析一下，如果我们使用小顶堆来解决问题，我们最多需要多少的时间复杂度呢？答案很明显。由于我们限制了这个小顶堆的大小是$k$，也就是说我们每次加入新元素再进行堆维护的时候只需要$\log_2 k$的时间，而我们就算是每个数字都进入堆（都大于堆顶元素），那么我们的时间复杂度也只有$n\log_2 k$也是小于$n\log_2 n$的。因此在数据量极大的情况下，我们可以很好的降低运行时间。

八、排序方法-基本方法

说完了堆排序，我们在回归一些基础的排序方法。主要看一下所有排序的一个整体的时间复杂度情况（平均，最好，最坏）。

冒泡排序(稳定)	O(n^2)	O(n)	O(n^2) 每次冒泡最大值到末尾

快速排序(不稳定)	O(nlogn)	O(nlogn)	O(n^2) pivot

归并排序(稳定)	O(nlogn)	O(nlogn)	O(nlogn) 分治法

选择排序(不稳定)	O(n^2)	O(n^2)	O(n^2) 有序和无序

直接插入排序(稳定)	O(n^2)	O(n)	O(n^2) 有序和无序

堆排序(不稳定)	O(nlogn)	O(nlogn)	O(nlogn)

## python语言基础

一、 assert 用法:

assert的语法如下：

```python
assert expression
```

他的等价语句如下：

```python
if not expression:
    raise AssertionError
```

也就是说当我们的程序可能出现问题的时候，我们与其等到运行程序后报错，不如我们在检测到后直接报错。

二、python的标准库
正则库re，sys，os，time，math

三、python的迭代器，生成器，修饰器

* 迭代器：首先**可迭代对象**指的是list，set，dic这种可以通过for循环遍历的对象，通过一下语句可以判断其是不是可迭代对象。

```python
from collections import iterable
isinstance('abc',iterable)
```

* 因此当我们使用iter()时就可以将可迭代对象变成一个**迭代器**。这时候他会多出一个方法叫做next，可以循环调用下一个元素，这也是for循环的本质。在itertools里面有很多常见的迭代器比如count计数器以及cycle无限循环序列。需要注意的是，迭代器中途不能改变值。

* 生成器：是迭代器的特殊形式，如果列表中某个元素可以通过某种算法推出来，那么我们就不必创建整个list，通过***一边循环，一边计算***，这样可以省下空间。生成器可以中途改变值，但是需要注意，他只能循环遍历一次。

```python
# 比如列表生成器
(x*x for x in range(10))

# 再比如生成器函数
def gnrt():
    yield 'first'
    yield 'second'
    yield 'third'

gnrt().next()
# output: first
gnrt().next()
# output: second
```

* 装饰器（简要叙述，门道太多）：装饰器可谓是python的一大杀器。他本身其实就是个函数。当我们使用其他函数的时候，我们希望加入一些类似日志信息等额外信息，比如我们在执行某个函数之前想要打印正在执行这个函数的信息，我们就可以通过创建一个**装饰器**，定义函数的时候先用@声明我需要调用这个装饰器了，最后再调用相应的函数，这样一来我们就可以把函数放在装饰器中封装起来了。具体例子如下。

```python
# 定义一个装饰器函数

# 第一层用来传入装饰器的参数

def use_log(level):
    # 第二层传入我们我们想用的func

    def decorator(func):
        # 第三层执行装饰器的语言

        def wrapper(*args, **kwargs):
            if level == "warn":
                logging.warn("%s is running" % func.__name__)
            # 逐层返回

            return func(*args)
        return wrapper

    return decorator

# 定义函数前先声明装饰器

@use_log(level="warn")

# 再去调用函数

def foo(name='foo'):
    print("i am %s" % name)

foo()
```

四、什么是进程，线程和协程

* 进程：我们先说最容易理解的**进程**。进程是一个实体。每个进程都有自己的地址空间(CPU分配)。具有独立功能的程序在某个数据集上的一次运行活动。
  
* 并发与并行：**并发**是在操作系统中，某一时间段，几个程序在同一个CPU上运行，但在任意一个时间点上，只有一个程序在CPU上运行，微观上这些程序是分时交替执行。而**并行**指的是当操作系统有多个CPU时，一个CPU处理A线程，另一个CPU处理B线程，两个线程互相不抢占CPU资源，可以同时进行，这种方式成为并行。
  
* 线程：进程拥有自己的资源空间，一个进程包含若干个**线程**，线程与CPU资源分配无关，多个线程共享同一进程内的资源。
  
* 协程：**协程**是一种比线程更加轻量级的存在，最重要的是，协程不被操作系统内核管理，协程是完全由程序控制的。

## 统计，逻辑方法

机器学习当然离不开基础数学知识了，面试中经常会随机的问我们一些类似概率论，统计学，还有基本的逻辑题，有一些常见的题型在这里做出一点小小总结。

一、假设检验的基本流程

在统计学习中，我们经常会用到假设检验。比如在多元线性回归中，我们需要知道某个自变量对因变量的贡献，或者说某个特征在整个模型中到底有没有用，这时候我们就需要通过假设检验来完成。具体的：

* 确定原假设以及备择假设，这里原假设是某个系数=0
* 构造统计量，常用统计量有t，z等
* 计算统计量的值
* 确定显著性水平，这样可以确定拒绝域的大小
* 判断统计量是否落在拒绝域内，如果是，拒绝原假设（同样意味着p-value很小）
  
二、常见逻辑题

* [病马问题，多次买卖问题，进一次房间判断灯开关，蒙眼翻硬币问题](https://blog.csdn.net/zmywly/article/details/41042033)
* 真假话问题，这种问题一般直接看哪两句话明显有矛盾，如果只有一句真话或假话，有矛盾的必然一真一假，这样**剩下的两句话**瞬间可以被判断出是真还是假[例子在这](http://www.offcn.com/xingce/2019/0417/11598.html)。
* [八道经典逻辑题](https://blog.csdn.net/weixin_34247155/article/details/94453593)

## 数据库

一、SQL语言的三种分类

* DML：数据操纵语言，常见有增删改查合并等。
* DDL：数据定义语言，常见包括创建数据结构，修改数据库结构，删除数据库结构，更改数据库对象的名称。
* DCL：数据控制语言，修改数据库结构的操作权限。CRANT授予和REVOKE收回。

二、实操题目

数据库其实就是练练练，先拿这50道题上手，基本面试的题目都不会超过这个难度。

* [数据库面试50题](https://zhuanlan.zhihu.com/p/53302593)


## 处理海量数据

## 评价方法总结

## 华为主管面试准备

## Reference
1. [方差偏差分析](https://zhuanlan.zhihu.com/p/38853908)
2. [GBDT的理解](https://www.cnblogs.com/bnuvincent/p/9693190.html?from=groupmessage&isappinstalled=0)
3. [常见面试题汇总](https://zhuanlan.zhihu.com/p/82105066?from=groupmessage&isappinstalled=0)
4. [python数据结构](https://python-data-structures-and-algorithms.readthedocs.io/zh/latest/06_%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90/big_o/)
5. [python迭代器，生成器和装饰器](https://www.jianshu.com/p/efaa19594cf4)
6. [进程，线程，协程](https://zhuanlan.zhihu.com/p/43373955)


